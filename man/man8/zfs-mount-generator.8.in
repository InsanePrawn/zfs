.\"
.\" Copyright 2018 Antonio Russo <antonio.e.russo@gmail.com>
.\" Copyright 2019 Kjeld Schouten-Lebbing <kjeld@schouten-lebbing.nl>
.\" Copyright 2020 InsanePrawn <insane.prawny@gmail.com>
.\"

.TH "ZFS\-MOUNT\-GENERATOR" "8" "2020-01-14" "ZFS" "zfs-mount-generator" "\""

.SH "NAME"
zfs\-mount\-generator \- generates systemd mount units for ZFS
.SH SYNOPSIS
.B /lib/systemd/system-generators/zfs\-mount\-generator
.sp
.SH DESCRIPTION
zfs\-mount\-generator implements the \fBGenerators Specification\fP
of
.BR systemd (1),
and is called during early boot to generate
.BR systemd.mount (5)
units for automatically mounted datasets. Mount ordering and dependencies
are created for all tracked pools (see below). If a dataset has
.BR mountpoint
set and
.BR canmount
is either
.BR on
or
.BR noauto ,
a mount unit will be generated.
If
.BR canmount
is
.BR on ,
the
.BR auto
mount option will be set, and a dependency for
.BR local-fs.target
on the mount will be created.

Because zfs pools may not be available very early in the boot process,
information on ZFS mountpoints must be stored separately. The output
of the command
.PP
.RS 4
zfs list -H -o name,mountpoint,canmount,atime,relatime,devices,exec,readonly,setuid,nbmand,encroot,keylocation,org.open-zfs.systemd:noauto,org.open-zfs.systemd:requires,org.open-zfs.systemd:requires-mounts-for,org.open-zfs.systemd:before,org.open-zfs.systemd:after,org.open-zfs.systemd:wanted-by,org.open-zfs.systemd:nofail,org.open-zfs.systemd:ignore

.RE
.PP
for datasets that should be mounted by systemd, should be kept
separate from the pool, at
.PP
.RS 4
.RI @sysconfdir@/zfs/zfs-list.cache/ POOLNAME
.
.RE
.PP
The cache file, if writeable, will be kept synchronized with the pool
state by the ZEDLET
.PP
.RS 4
history_event-zfs-list-cacher.sh .
.RE
.PP
.sp
.SS PROPERTIES
The behavior of the generator script can be influenced by setting special properties on datasets:
.sp
.TP 4
.BR org.open\-zfs.systemd:noauto
Create and treat the mount unit as if it had
.BR canmount=noauto
set.
.TP 4
.BR org.open\-zfs.systemd:requires\-mounts\-for
Space\-separated list of mountpoints to require to be mounted by this mount unit
.TP 4
.BR org.open\-zfs.systemd:before
Space\-separated list of units to order after this mount unit
.TP 4
.BR org.open\-zfs.systemd:after
Space\-separated list of units to order before this mount unit
.TP 4
.BR org.open\-zfs.systemd:wanted\-by
Unit to add a dependency for this mount unit to.
Defaults to
.BR local\-fs.target
if unset.
Setting this property to
.BR none
will result in similar behavior to
.BR noauto .
.TP 4
.BR org.open\-zfs.systemd:nofail
Toggles between a
.BR wants
and
.BR requires
type of dependency between the
.TP 4
.BR org.open\-zfs.systemd:ignore
Do not generate a mount unit for this dataset.

.RE
See also
.BR systemd.mount (5)

.PP
.SH EXAMPLE
To begin, enable tracking for the pool:
.PP
.RS 4
touch
.RI @sysconfdir@/zfs/zfs-list.cache/ POOLNAME
.RE
.PP
Then, enable the tracking ZEDLET:
.PP
.RS 4
ln -s "@zfsexecdir@/zed.d/history_event-zfs-list-cacher.sh" "@sysconfdir@/zfs/zed.d"

systemctl enable zfs-zed.service

systemctl restart zfs-zed.service
.RE
.PP
Force the running of the ZEDLET by setting a monitored property, e.g.
.BR canmount
for at least one dataset in the pool:
.PP
.RS 4
zfs set canmount=on
.I DATASET
.RE
.PP
This forces an update to the stale cache file.
.sp
.SH SEE ALSO
.BR zfs (5)
.BR zfs-events (5)
.BR zed (8)
.BR zpool (5)
.BR systemd (1)
.BR systemd.target (5)
.BR systemd.special (7)
.BR systemd.mount (7)
